---
title: "Tarea 3 Algoritmos e IA"
author: "Lucia Martinez, Carlos Garcia y Estefani Casallas"
date: "2025-01-19"
output: html_document
---

# Actividad Grupal Algoritmos e IA 

*Análisis de un conjunto de datos de origen biológico mediante técnicas de machine learning supervisadas y no supervisadas*

## Preparación del entorno de trabajo (instalación y carga de paquetes)

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE, # Hace que el código se muestre en el html
                      message = FALSE, # Para no mostrar los mensajes
                      warning = FALSE, # Para no mostrar los avisos
                      fig.align = 'center' # Para que las figuras salgan alineadas en el html
)

# Creo que la instalación de paquetes debería ir en cada chunk, cada uno sabe lo que pone para su parte del trabajo. Cuando esté completo trasladamos las líneas de código de instalación a esta parte.
library()

```

## Depurado del conjunto de datos

```{r cargar_datos}
rm(list=ls())
path<- "C:/Users/lulim/OneDrive/Documentos/GitHub/Analisis-biologico-con-Machine-Learning/muestras"
setwd(path)

# Carga de datos 
classes <- read.csv ("C:/Users/lulim/OneDrive/Documentos/GitHub/Analisis-biologico-con-Machine-Learning/muestras/classes.csv", sep = ";", header = FALSE)
gene_expression<- read.csv("C:/Users/lulim/OneDrive/Documentos/GitHub/Analisis-biologico-con-Machine-Learning/muestras/gene_expression.csv", sep = ";", header = FALSE)
column_names<- read.csv("C:/Users/lulim/OneDrive/Documentos/GitHub/Analisis-biologico-con-Machine-Learning/muestras/column_names.txt", sep = ";", header = FALSE)

# Creación de un df aglomerando los archivos cargados
data <- gene_expression
colnames(data)<-column_names[,1]
row.names(data)<-classes[,1]
data<- cbind(data,clases = classes[,2]

#---> yo eliminaria estas dos lineas
dim(data) # Compruebo que las dimensiones del df son, para las columnas, una unidad mayor que en el df "gene_expression"
table(data[,501]) # Compruebo el contenido de la nueva columna
      
# Imputación de los NA
anyNA(data) # No hay valores missing en el df
# na.omit(data) # En caso de haberlos, esta función elimina las filas que tengan un NA
# dim (data) # Para saber si se han eliminado filas usaríamos dim()

# Otros tipos de procesamiento
sumas<- colSums(data[1:500], na.rm = FALSE, dims = 1 ) # Suma de los datos por columnas
columnascero <- names(sumas[sumas==0]) # Se extraen los nombres de las columnas cuyas sumas son == 0
data <- data[, !names(data) %in% columnascero] #  Eliminación de las columnas

# Se muestran los columnas (genes) que se han excluido del df
print(paste("Los genes eliminados son: ", paste(columnascero[1:3], collapse = ", ")))

data[] <- lapply(data, function(x) if(is.character(x)) factor(x) else x)#transformamos las variables categóricas en factores
data_num <- data.frame(sapply(data[,1:(ncol(data) - 1)], as.numeric)) # Conversión de los valores de expresión a numéricos.
sc_data_num <- scale(data_num[,1:(ncol(data) - 1)])# Escalado de los datos
colSums(is.na(data_num)) # Revisión de que tras el transformado no se han generado valores NA
colSums(is.na(sc_data_num))

# Guardado de datos
# write.csv(data_num, "data_num.csv", row.names = FALSE)
# sc_data_num_df <- as.data.frame(sc_data_num) # Conversión de la matriz a un data frame 
# write.csv(sc_data_num_df, "sc_data_num.csv", row.names = FALSE)
```

**¿Qué método habéis escogido para llevar a cabo la imputación de los datos? Razonad vuestra respuesta. (0,3 puntos)**

Para eliminar datos que no son útiles para el desarrollo de esta tarea, y que posiblemente contribuirían a generar ruido en los resultados de la misma, se eliminaron aquellos genes que no se expresaban en ninguna muestra. En concreto 3 : "MIER3", "ZCCHC12" y "RPL22L1". Para ello, se realizó una suma por columnas de los datos de expresión con la función *colSums()*, y con el comando  *columnascero <- names(sumas[sumas==0])* se identificaron los genes no expresados para luego eliminarlos.

**¿Habéis llevado a cabo algún otro tipo de procesamiento? Razonad vuestra respuesta. (0,2 puntos).**

En previsión del uso de los datos de expresión en los apartados posteriores de la tarea, se han transformado a numéricos (indispensable en algunos algoritmos) y se han escalado los valores de expresión génica. Este último paso permite nivelar la magnitud de expresión de los genes entre sí, favoreciendo que nuestras conclusiones se basen en razones biológicas relevantes, y no simplemente en diferencias en la magnitud de expresión de genes que no tengan que ver con la patología o condición de estudio, sino con la forma en la que se transcriben los genes en el ser humano.

## Implementación de cuatro métodos de aprendizaje no supervisado

En esta sección se implementarán los métodos X e Y de reducción de dimensionalidad, y W y Z de clusterización.

```{r}

```

**¿Cuál es el motivo por el cual habéis seleccionado estas técnicas de reducción de dimensionalidad? (0,3 puntos).**

Blablabla

**¿Cuál es el motivo por el cual habéis seleccionado estas técnicas de clusterización? (0,3 puntos).**

Blablabla

**En ambos casos, ¿qué aspectos positivos y negativos tienen cada una? (0,2 puntos).**

Blablabla

**En el caso de la clusterización, ¿podéis afirmar con certeza que los clústeres generados son los mejores posibles? Razonad vuestra respuesta. (0,2 puntos).**

Blablabla

## Implementación de tres métodos de aprendizaje supervisado y cálculo de métricas de evaluación

```{r aprendizaje_supervisado}
# Instalar paquetes y cargar librerias correspondientes
install.packages(c("here", "caret", "randomForest", "e1071", "gbm", "kableExtra"))
library(caret)
library(randomForest)
library(e1071)
library(gbm)
library(kableExtra)

# Dividir datos en entrenamiento y prueba
set.seed(123)
train_index <- createDataPartition(data$Class, p = 0.8, list = FALSE)
train_data <- data[train_index, ]
test_data <- data[-train_index, ]
# para reflejar su rendimiento real y evitar sobreajustes.

# Modelo RF
rf_model <- randomForest(Class ~ ., data = train_data, importance = TRUE)
rf_pred <- predict(rf_model, test_data)
rf_metrics <- confusionMatrix(rf_pred, test_data$Class)
# Entrena el modelo de RF y calcula métricas con "confusionMatrix".

# Modelo SVM
svm_model <- train(Class ~ ., data = train_data, method = "svmLinear")
svm_pred <- predict(svm_model, test_data)
svm_metrics <- confusionMatrix(svm_pred, test_data$Class)
# Entrena el modelo SVM con kernel lineal.

# Modelo Gradient Boosting Machines (GBM)
gbm_model <- train(
  Class ~ ., 
  data = train_data, 
  method = "gbm", 
  verbose = FALSE, 
  trControl = trainControl(method = "cv", number = 5)
)
gbm_pred <- predict(gbm_model, test_data)
gbm_metrics <- confusionMatrix(gbm_pred, test_data$Class)
# Entrena el modelo GBM con validación cruzada.

# Comparar resultados
accuracy <- c(
  "Random Forest" = rf_metrics$overall["Accuracy"],
  "SVM" = svm_metrics$overall["Accuracy"],
  "GBM" = gbm_metrics$overall["Accuracy"]
)
best_model <- names(which.max(accuracy))
# Calcula la precisión e identifica el mejor modelo según la precisión

# Crear tabla de resultados
library(knitr)
library(kableExtra)

resultados_modelos <- data.frame(
  Modelo = c("Random Forest", "SVM", "GBM"),
  Precisión = round(as.numeric(accuracy), 4)
)

# Tabla de resultados
kable(resultados_modelos, caption = "Precisión de los modelos evaluados") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)

#  Métricas detalladas
kable(as.data.frame(rf_metrics$table), caption = "Matriz de confusión - Random Forest") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

kable(as.data.frame(svm_metrics$table), caption = "Matriz de confusión - SVM") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

kable(as.data.frame(gbm_metrics$table), caption = "Matriz de confusión - GBM") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# Resaltar el mejor modelo
cat("\nEl modelo con mejor rendimiento fue:", best_model, "con una precisión de:", max(accuracy), "\n")

```

**¿Cuál es el motivo por el cual habéis seleccionado ambas técnicas de aprendizaje supervisado? ¿Cuál ha dado mejores resultados a la hora de clasificar las muestras? Razonad vuestra respuesta (1 punto).**

Se ha seleccionado los modelos Random Forest (RF), Support Vector Machines (SVM) y  Gradient Boosting Machines (GBM) como técnicas de aprendizaje supervisado debido a sus características específicas:

*- RF:* Es robusto frente a ruido, maneja datos con características no lineales, y proporciona métricas de importancia para las variables, lo cual es útil en datasets complejos de expresion génica.

*- SVM:* Es eficiente para datasets con alta dimensionalidad y permite utilizar kernels para modelar relaciones complejas entre variables.

*- GBM:* Captura relaciones complejas entre variables gracias a su enfoque iterativo y basado en boosting. Tambien ofrece flexibilidad mediante ajuste de hiperparámetros.

Tras la implementación, los modelos RF y SVM presentaron una mayor precisión al clasificar las muestras comparado con GBM, posiblemente porque Random Forest maneja mejor datasets con muchas características (como en el caso de la expresión génica) y SVM presenta una gran capacidad para encontrar hiperplanos optimos y trabajar bien con datos de  alta dimensionalidad. Mientras que GMB podría haberse visto afectado por la escala y la relación entre variables.

**¿Habéis considerado oportuno implementar algún método de reducción de dimensionalidad para procesar los datos antes de implementarlos en dichas técnicas? ¿Por qué? (0,5 puntos).**

Sí, se considera oportuno implementar PCA para reducir la dimensionalidad de los datos. La alta dimensionalidad de los datos de expresión génica puede introducir redundancia y ruido. PCA permite capturar el 85% de la varianza total con solo 10 componentes principales, como se observa en el gráfico de varianza explicada, lo que optimiza el análisis al reducir la complejidad sin perder información relevante.

Además, la tabla de comparación de precisión demuestra que los modelos supervisados ​​mantienen un rendimiento similar tras aplicar PCA, validando la utilidad para simplificar los datos sin comprometer el desempeño.

```{r aprendizaje_supervisadoPCA}
# Reducción de dimensionalidad con PCA
pca <- prcomp(data[, -ncol(data)], scale. = TRUE)
pca_data <- data.frame(pca$x[, 1:10])  # Mantener las primeras 10 componentes principales
pca_data$Class <- data$Class

# Dividir datos PCA en entrenamiento y prueba
set.seed(123)
train_index <- createDataPartition(pca_data$Class, p = 0.8, list = FALSE)
train_data_pca <- pca_data[train_index, ]
test_data_pca <- pca_data[-train_index, ]

# Modelo Random Forest con PCA
rf_pca_model <- randomForest(Class ~ ., data = train_data_pca, importance = TRUE)
rf_pca_pred <- predict(rf_pca_model, test_data_pca)
rf_pca_metrics <- confusionMatrix(rf_pca_pred, test_data_pca$Class)

# Comparar precisión con modelos originales
accuracy_comparison <- data.frame(
  Modelo = c("Random Forest", "SVM", "GBM", "RF (PCA)"),
  Precisión = c(
    rf_metrics$overall["Accuracy"],
    svm_metrics$overall["Accuracy"],
    gbm_metrics$overall["Accuracy"],
    rf_pca_metrics$overall["Accuracy"]
  )
)

# Tabla de comparación
kable(accuracy_comparison, caption = "Comparación de la precisión de los modelos") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))

```

**¿Qué aspectos positivos y negativos tienen cada una de las técnicas que habéis escogido? (0,25 puntos).**

*- RF:* 
  
  Positivo: Robusto frente a ruido y datos faltantes; proporciona información sobre la importancia de las variables.
  
  Negativo: Propenso a sobreajustarse si los hiperparámetros no se ajustan adecuadamente; puede ser computacionalmente costoso.

*- SVM:*
  
  Positivo: Eficaz en datasets de alta dimensionalidad; permite modelar relaciones no lineales mediante kernels.
  
  Negativo: Requiere preprocesamiento de datos (normalización); El ajuste de hiperparámetros puede ser complejo.

*- GBM:*

  Positivo: Captura relaciones complejas entre variables gracias al enfoque iterativo.
  
  Negativo: Sensible al ajuste de hiperparámetros y al sobreajuste; computacionalmente más demandante.

## Pregunta final

**De estas cuatro opciones (Red de perceptrones, Redes convolucionales, Redes recurrentes y Redes de grafos), ¿qué tipo de arquitectura de deep learning sería la más adecuada para procesar datos de expresión génica? Razonad vuestra respuesta (0,25 puntos).**

La arquitectura más adecuada para datos de expresión génica es una Red de Perceptrones (MLP) , ya que los datos suelen ser tabulares o vectores de características, sin estructuras espaciales, secuenciales o en forma de gráficos. MLP es eficiente para capturar relaciones entre variables en este tipo de datos.
